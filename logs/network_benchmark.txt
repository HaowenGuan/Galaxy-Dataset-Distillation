C:\Users\EXCAE\PycharmProjects\Galaxy-Dataset-Distillation\venv\Scripts\python.exe C:/Users/EXCAE/PycharmProjects/Galaxy-Dataset-Distillation/model_benchmark.py
100%|██████████| 8050/8050 [00:00<00:00, 536185.66it/s]
BUILDING training DATASET
BUILDING testing DATASET
100%|██████████| 2013/2013 [00:00<00:00, 38678.16it/s]
real images channel 0, mean = -0.0012, std = 0.9841
real images channel 1, mean = -0.0003, std = 0.9838
real images channel 2, mean = 0.0001, std = 0.9832
Benchmarking galaxy -------------------------------------------------------------------
100%|██████████| 32/32 [00:02<00:00, 11.39it/s]
100%|██████████| 8/8 [00:00<00:00, 47.02it/s]
Training loss at epoch 0: 2530.295432932599, test loss: 7.984243530334078
100%|██████████| 32/32 [00:01<00:00, 19.96it/s]
100%|██████████| 8/8 [00:00<00:00, 52.58it/s]
Training loss at epoch 1: 6.797520395598797, test loss: 6.692055593718952
100%|██████████| 32/32 [00:01<00:00, 19.13it/s]
100%|██████████| 8/8 [00:00<00:00, 51.57it/s]
Training loss at epoch 2: 6.552916729850058, test loss: 6.401381620055576
100%|██████████| 32/32 [00:01<00:00, 19.91it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 3: 6.305463033166731, test loss: 6.0022193995862825
100%|██████████| 32/32 [00:01<00:00, 19.86it/s]
100%|██████████| 8/8 [00:00<00:00, 51.90it/s]
Training loss at epoch 4: 5.588697729643828, test loss: 6.26334210929738
100%|██████████| 32/32 [00:01<00:00, 19.93it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 5: 5.142346873786879, test loss: 4.266537283050795
100%|██████████| 32/32 [00:01<00:00, 19.89it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 6: 4.467631616059298, test loss: 4.710872977986836
100%|██████████| 32/32 [00:01<00:00, 19.91it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 7: 4.586684718161636, test loss: 4.239562442512342
100%|██████████| 32/32 [00:01<00:00, 19.94it/s]
100%|██████████| 8/8 [00:00<00:00, 52.58it/s]
Training loss at epoch 8: 3.7724389686347535, test loss: 3.4832964090346343
100%|██████████| 32/32 [00:01<00:00, 19.96it/s]
100%|██████████| 8/8 [00:00<00:00, 51.90it/s]
Training loss at epoch 9: 3.6289363808957686, test loss: 3.499740062397153
100%|██████████| 32/32 [00:01<00:00, 19.91it/s]
100%|██████████| 8/8 [00:00<00:00, 52.93it/s]
Training loss at epoch 10: 3.5116345366483888, test loss: 3.3280985605284403
100%|██████████| 32/32 [00:01<00:00, 20.03it/s]
100%|██████████| 8/8 [00:00<00:00, 52.93it/s]
Training loss at epoch 11: 3.3316644287109374, test loss: 3.210852117486339
100%|██████████| 32/32 [00:01<00:00, 20.07it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 12: 3.301592418599573, test loss: 3.1144449809150676
100%|██████████| 32/32 [00:01<00:00, 20.02it/s]
100%|██████████| 8/8 [00:00<00:00, 51.90it/s]
Training loss at epoch 13: 3.2846688861728457, test loss: 3.508029230897603
100%|██████████| 32/32 [00:01<00:00, 20.08it/s]
100%|██████████| 8/8 [00:00<00:00, 51.90it/s]
Training loss at epoch 14: 3.2500113388914498, test loss: 2.9848047626948273
100%|██████████| 32/32 [00:01<00:00, 20.07it/s]
100%|██████████| 8/8 [00:00<00:00, 52.58it/s]
Training loss at epoch 15: 3.0268091805973407, test loss: 3.01551769576852
100%|██████████| 32/32 [00:01<00:00, 20.06it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 16: 2.9797355775063084, test loss: 2.907251940754238
100%|██████████| 32/32 [00:01<00:00, 20.03it/s]
100%|██████████| 8/8 [00:00<00:00, 52.58it/s]
Training loss at epoch 17: 3.0576308654406055, test loss: 3.279358668168623
100%|██████████| 32/32 [00:01<00:00, 20.07it/s]
100%|██████████| 8/8 [00:00<00:00, 41.41it/s]
Training loss at epoch 18: 3.0084892054966517, test loss: 2.875160759264003
100%|██████████| 32/32 [00:01<00:00, 19.76it/s]
100%|██████████| 8/8 [00:00<00:00, 49.64it/s]
Training loss at epoch 19: 2.7838878219320167, test loss: 2.6187937888587465
100%|██████████| 32/32 [00:01<00:00, 19.05it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 20: 2.7255169601914306, test loss: 3.0409549840101837
100%|██████████| 32/32 [00:01<00:00, 19.27it/s]
100%|██████████| 8/8 [00:00<00:00, 49.03it/s]
Training loss at epoch 21: 2.7530589834651593, test loss: 2.5396724877165613
100%|██████████| 32/32 [00:01<00:00, 19.35it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 22: 2.5685121524407997, test loss: 2.3901160704929674
100%|██████████| 32/32 [00:01<00:00, 19.55it/s]
100%|██████████| 8/8 [00:00<00:00, 49.04it/s]
Training loss at epoch 23: 2.5121862603418577, test loss: 2.76903969413655
100%|██████████| 32/32 [00:01<00:00, 19.36it/s]
100%|██████████| 8/8 [00:00<00:00, 48.74it/s]
Training loss at epoch 24: 2.569982697860054, test loss: 2.390393654623851
100%|██████████| 32/32 [00:01<00:00, 19.54it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 25: 2.414199313525087, test loss: 2.3340147864563927
100%|██████████| 32/32 [00:01<00:00, 19.88it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 26: 2.3514187754755436, test loss: 2.3446719856091653
100%|██████████| 32/32 [00:01<00:00, 19.99it/s]
100%|██████████| 8/8 [00:00<00:00, 52.24it/s]
Training loss at epoch 27: 2.39788267147467, test loss: 2.3441045678674555
100%|██████████| 32/32 [00:01<00:00, 20.01it/s]
100%|██████████| 8/8 [00:00<00:00, 51.90it/s]
Training loss at epoch 28: 2.2736313453816477, test loss: 2.2528396204698753
100%|██████████| 32/32 [00:01<00:00, 19.94it/s]
100%|██████████| 8/8 [00:00<00:00, 52.58it/s]
Training loss at epoch 29: 2.379553491817498, test loss: 2.438610472965762
Benchmarking ConvNet -------------------------------------------------------------------
100%|██████████| 32/32 [00:01<00:00, 18.88it/s]
100%|██████████| 8/8 [00:00<00:00, 54.37it/s]
Training loss at epoch 0: 27.73618964722438, test loss: 7.09173744682998
100%|██████████| 32/32 [00:01<00:00, 20.08it/s]
100%|██████████| 8/8 [00:00<00:00, 54.37it/s]
Training loss at epoch 1: 4.851854361776979, test loss: 3.303450575410224
100%|██████████| 32/32 [00:01<00:00, 20.11it/s]
100%|██████████| 8/8 [00:00<00:00, 52.93it/s]
Training loss at epoch 2: 2.4594286389084337, test loss: 1.794604616501529
100%|██████████| 32/32 [00:01<00:00, 20.13it/s]
100%|██████████| 8/8 [00:00<00:00, 54.37it/s]
Training loss at epoch 3: 1.627034260056774, test loss: 1.7832010025653564
100%|██████████| 32/32 [00:01<00:00, 20.15it/s]
100%|██████████| 8/8 [00:00<00:00, 54.00it/s]
Training loss at epoch 4: 1.5031335487128785, test loss: 1.2480792876090567
100%|██████████| 32/32 [00:01<00:00, 20.09it/s]
100%|██████████| 8/8 [00:00<00:00, 54.37it/s]
Training loss at epoch 5: 1.2890114048549106, test loss: 1.190709485027012
100%|██████████| 32/32 [00:01<00:00, 19.92it/s]
100%|██████████| 8/8 [00:00<00:00, 54.00it/s]
Training loss at epoch 6: 1.2588245273376844, test loss: 1.1458403828483994
100%|██████████| 32/32 [00:01<00:00, 20.13it/s]
100%|██████████| 8/8 [00:00<00:00, 54.00it/s]
Training loss at epoch 7: 1.2049039644039936, test loss: 1.2762971319965148
100%|██████████| 32/32 [00:01<00:00, 20.15it/s]
100%|██████████| 8/8 [00:00<00:00, 53.28it/s]
Training loss at epoch 8: 1.1150369016280086, test loss: 1.0453903039059589
100%|██████████| 32/32 [00:01<00:00, 20.04it/s]
100%|██████████| 8/8 [00:00<00:00, 53.64it/s]
Training loss at epoch 9: 1.0871022564431896, test loss: 1.0013633610535426

Process finished with exit code 0
